{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### DL LAB 2A"
      ],
      "metadata": {
        "id": "5fRGY3TUZ-GP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HU2EOx01WXqT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\"\n",
        "columns = ['letter', 'x-box', 'y-box', 'width', 'height', 'onpix', 'x-bar', 'y-bar', 'x2bar', 'y2bar', 'xybar',\n",
        "           'x2ybr', 'xy2br', 'x-ege', 'xegvy', 'y-ege', 'yegvx']\n",
        "data = pd.read_csv(url, names=columns)"
      ],
      "metadata": {
        "id": "1jgaZbEuWYUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Separate features and labels\n",
        "X = data.drop('letter', axis=1).values\n",
        "y = data['letter'].values"
      ],
      "metadata": {
        "id": "8a4BM7c39V2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Encode labels (A-Z -> 0-25)\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "y_categorical = to_categorical(y_encoded)"
      ],
      "metadata": {
        "id": "6j23oTLfWrED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42, stratify=y_categorical)"
      ],
      "metadata": {
        "id": "mFdOm1qKWzwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "m7J9a8xkW1W2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Build the DNN model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(16,)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(26, activation='softmax')  # 26 letters A-Z\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "zwJggL1YW3Er",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec052211-1279-41b1-9efd-ae72137a6964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)"
      ],
      "metadata": {
        "id": "OWA40Dr4W5FE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3151d52c-ad93-4b16-dc37-3cf6d2c82b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4202 - loss: 2.1547 - val_accuracy: 0.7656 - val_loss: 0.8309\n",
            "Epoch 2/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7861 - loss: 0.7571 - val_accuracy: 0.8219 - val_loss: 0.6093\n",
            "Epoch 3/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8391 - loss: 0.5472 - val_accuracy: 0.8475 - val_loss: 0.4883\n",
            "Epoch 4/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8724 - loss: 0.4415 - val_accuracy: 0.8763 - val_loss: 0.4047\n",
            "Epoch 5/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8914 - loss: 0.3735 - val_accuracy: 0.8969 - val_loss: 0.3495\n",
            "Epoch 6/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.3173 - val_accuracy: 0.9025 - val_loss: 0.3078\n",
            "Epoch 7/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9196 - loss: 0.2749 - val_accuracy: 0.9175 - val_loss: 0.2666\n",
            "Epoch 8/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9370 - loss: 0.2283 - val_accuracy: 0.9125 - val_loss: 0.2520\n",
            "Epoch 9/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9417 - loss: 0.2093 - val_accuracy: 0.9262 - val_loss: 0.2312\n",
            "Epoch 10/10\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9470 - loss: 0.1810 - val_accuracy: 0.9256 - val_loss: 0.2153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOXR5POVXAlE",
        "outputId": "93e13376-f172-4673-8427-332160246ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"DNN.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlQ11mf3XQT1",
        "outputId": "ed1a6921-ba3c-48c0-9acb-56f99273a2ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw25kXZtXC00",
        "outputId": "1994b7a1-cd69-4c4f-af57-36678f855687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9212 - loss: 0.2677\n",
            "Test Accuracy: 0.9230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Make predictions (optional)\n",
        "y_pred = model.predict(X_test)\n",
        "predicted_labels = label_encoder.inverse_transform(np.argmax(y_pred, axis=1))"
      ],
      "metadata": {
        "id": "qFX4ZQayXoRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61e6fea-ff95-456b-9e8b-fcbcc8e0057f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def random_sample_predict(model, scaler, label_encoder, X_test, y_test):\n",
        "    # Pick a random index\n",
        "    idx = random.randint(0, len(X_test) - 1)\n",
        "\n",
        "    # Select random sample\n",
        "    sample = X_test[idx].reshape(1, -1)\n",
        "    true_label = np.argmax(y_test[idx])\n",
        "    true_letter = label_encoder.inverse_transform([true_label])[0]\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(sample)\n",
        "    predicted_class = np.argmax(prediction, axis=1)\n",
        "    predicted_letter = label_encoder.inverse_transform(predicted_class)[0]\n",
        "\n",
        "    print(f\"\\n--- Random Sample Test ---\")\n",
        "    print(f\"True Letter: {true_letter}\")\n",
        "    print(f\"Predicted Letter: {predicted_letter}\")\n",
        "\n",
        "# Call this function after model training\n",
        "random_sample_predict(model, scaler, label_encoder, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBcPctkU_UdM",
        "outputId": "7b88ee9c-2bd1-46b0-b226-85f4313d1956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690ms/step\n",
            "\n",
            "--- Random Sample Test ---\n",
            "True Letter: K\n",
            "Predicted Letter: K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DL LAB 2B"
      ],
      "metadata": {
        "id": "ggxJX5bCZ3f-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Import Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# 2. Create a small custom dataset (manually for simplicity)\n",
        "texts = [\n",
        "    \"The movie was fantastic and thrilling\",\n",
        "    \"I hated the movie, it was boring and bad\",\n",
        "    \"An excellent movie with brilliant performances\",\n",
        "    \"The film was dull and too long\",\n",
        "    \"Loved the story and the acting was amazing\",\n",
        "    \"Terrible movie, complete waste of time\",\n",
        "    \"What a masterpiece, loved every moment\",\n",
        "    \"Worst movie ever, so disappointed\",\n",
        "    \"Absolutely stunning, a wonderful experience\",\n",
        "    \"I regret watching this movie, very bad\"\n",
        "]\n",
        "\n",
        "labels = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]  # 1 = Positive, 0 = Negative\n",
        "\n",
        "# 3. Tokenize the texts\n",
        "max_words = 1000\n",
        "max_len = 20\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# 4. Build the Model\n",
        "model = keras.Sequential([\n",
        "    layers.Embedding(input_dim=max_words, output_dim=64, input_length=max_len),\n",
        "    layers.Bidirectional(layers.LSTM(32)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 5. Compile Model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 6. Train the Model\n",
        "model.fit(padded_sequences, np.array(labels), epochs=20, batch_size=2, verbose=2)\n",
        "\n",
        "# 7. Real-time Prediction Function\n",
        "def predict_sentiment(review):\n",
        "    seq = tokenizer.texts_to_sequences([review])\n",
        "    padded = pad_sequences(seq, maxlen=max_len, padding='post')\n",
        "    pred = model.predict(padded, verbose=0)[0][0]\n",
        "    sentiment = \"Positive\" if pred >= 0.5 else \"Negative\"\n",
        "    print(f\"\\nReview Sentiment: {sentiment} (Score: {pred:.4f})\")\n",
        "\n",
        "# 8. Real-time Testing\n",
        "sample_review1 = \"The movie was fantastic! I really loved the performances.\"\n",
        "predict_sentiment(sample_review1)\n",
        "\n",
        "sample_review2 = \"The film was boring and too long. Not good at all.\"\n",
        "predict_sentiment(sample_review2)\n",
        "\n",
        "sample_review3 = \"I absolutely hated this movie. Worst experience ever.\"\n",
        "predict_sentiment(sample_review3)\n",
        "\n",
        "sample_review4 = \"An excellent masterpiece. Great story and acting.\"\n",
        "predict_sentiment(sample_review4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXitG_WRAujV",
        "outputId": "164705f1-15b9-47fb-a0da-096cdfde67a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "5/5 - 3s - 667ms/step - accuracy: 0.2000 - loss: 0.6958\n",
            "Epoch 2/20\n",
            "5/5 - 0s - 26ms/step - accuracy: 0.5000 - loss: 0.6915\n",
            "Epoch 3/20\n",
            "5/5 - 0s - 27ms/step - accuracy: 0.9000 - loss: 0.6847\n",
            "Epoch 4/20\n",
            "5/5 - 0s - 30ms/step - accuracy: 0.9000 - loss: 0.6790\n",
            "Epoch 5/20\n",
            "5/5 - 0s - 25ms/step - accuracy: 0.9000 - loss: 0.6702\n",
            "Epoch 6/20\n",
            "5/5 - 0s - 13ms/step - accuracy: 1.0000 - loss: 0.6568\n",
            "Epoch 7/20\n",
            "5/5 - 0s - 28ms/step - accuracy: 1.0000 - loss: 0.6376\n",
            "Epoch 8/20\n",
            "5/5 - 0s - 28ms/step - accuracy: 1.0000 - loss: 0.6084\n",
            "Epoch 9/20\n",
            "5/5 - 0s - 12ms/step - accuracy: 1.0000 - loss: 0.5669\n",
            "Epoch 10/20\n",
            "5/5 - 0s - 12ms/step - accuracy: 1.0000 - loss: 0.5026\n",
            "Epoch 11/20\n",
            "5/5 - 0s - 12ms/step - accuracy: 1.0000 - loss: 0.4084\n",
            "Epoch 12/20\n",
            "5/5 - 0s - 12ms/step - accuracy: 1.0000 - loss: 0.3190\n",
            "Epoch 13/20\n",
            "5/5 - 0s - 13ms/step - accuracy: 1.0000 - loss: 0.2097\n",
            "Epoch 14/20\n",
            "5/5 - 0s - 12ms/step - accuracy: 1.0000 - loss: 0.1371\n",
            "Epoch 15/20\n",
            "5/5 - 0s - 29ms/step - accuracy: 1.0000 - loss: 0.1244\n",
            "Epoch 16/20\n",
            "5/5 - 0s - 25ms/step - accuracy: 1.0000 - loss: 0.0723\n",
            "Epoch 17/20\n",
            "5/5 - 0s - 29ms/step - accuracy: 1.0000 - loss: 0.0535\n",
            "Epoch 18/20\n",
            "5/5 - 0s - 12ms/step - accuracy: 1.0000 - loss: 0.0297\n",
            "Epoch 19/20\n",
            "5/5 - 0s - 12ms/step - accuracy: 1.0000 - loss: 0.0178\n",
            "Epoch 20/20\n",
            "5/5 - 0s - 12ms/step - accuracy: 1.0000 - loss: 0.0147\n",
            "\n",
            "Review Sentiment: Positive (Score: 0.9385)\n",
            "\n",
            "Review Sentiment: Negative (Score: 0.0103)\n",
            "\n",
            "Review Sentiment: Negative (Score: 0.0103)\n",
            "\n",
            "Review Sentiment: Positive (Score: 0.9875)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# 2. Load the IMDB dataset (with raw text)\n",
        "imdb = keras.datasets.imdb\n",
        "\n",
        "# Set vocabulary size\n",
        "vocab_size = 10000\n",
        "\n",
        "# Load dataset (already preprocessed as integers)\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "# 3. Decode function to get back text\n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = {value: key for key, value in word_index.items()}\n",
        "\n",
        "def decode_review(text_ints):\n",
        "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in text_ints])\n",
        "\n",
        "# 4. Prepare data (pad sequences)\n",
        "maxlen = 200\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# 5. Build model\n",
        "model = keras.Sequential([\n",
        "    layers.Embedding(vocab_size, 64, input_length=maxlen),\n",
        "    layers.Bidirectional(layers.LSTM(64)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 6. Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 7. Train model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# 8. Real-time testing function\n",
        "def predict_sentiment_text(model, review_text):\n",
        "    # 8.1 Preprocessing: convert review to integers\n",
        "    words = review_text.lower().split()\n",
        "    review_seq = []\n",
        "    for word in words:\n",
        "        idx = word_index.get(word, 2)  # 2 is for unknown words\n",
        "        review_seq.append(idx)\n",
        "\n",
        "    review_seq = pad_sequences([review_seq], maxlen=maxlen)\n",
        "\n",
        "    pred = model.predict(review_seq, verbose=0)[0][0]\n",
        "    sentiment = \"Positive\" if pred >= 0.5 else \"Negative\"\n",
        "    print(f\"\\nReview Sentiment: {sentiment} (Score: {pred:.4f})\")\n",
        "\n",
        "# 9. Real examples\n",
        "sample_review1 = \"The movie was fantastic! I really loved the performances.\"\n",
        "predict_sentiment_text(model, sample_review1)\n",
        "\n",
        "sample_review2 = \"The film was boring and too long. Not good at all.\"\n",
        "predict_sentiment_text(model, sample_review2)\n",
        "\n",
        "sample_review3 = \"it is so disappointing.\"\n",
        "predict_sentiment_text(model, sample_review3)\n",
        "\n",
        "sample_review4 = \"An excellent movie. Great direction and amazing acting!\"\n",
        "predict_sentiment_text(model, sample_review4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3Rf5SzkDNtj",
        "outputId": "bef27cea-6221-410a-b8a1-3e7a914a1cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.7048 - loss: 0.5320 - val_accuracy: 0.8608 - val_loss: 0.3290\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9095 - loss: 0.2309 - val_accuracy: 0.8698 - val_loss: 0.3129\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9386 - loss: 0.1698 - val_accuracy: 0.8712 - val_loss: 0.3587\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.9677 - loss: 0.0999 - val_accuracy: 0.8642 - val_loss: 0.3867\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9743 - loss: 0.0769 - val_accuracy: 0.8638 - val_loss: 0.4658\n",
            "\n",
            "Review Sentiment: Negative (Score: 0.4940)\n",
            "\n",
            "Review Sentiment: Negative (Score: 0.2831)\n",
            "\n",
            "Review Sentiment: Negative (Score: 0.2314)\n",
            "\n",
            "Review Sentiment: Positive (Score: 0.9432)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ekyTq-yCEqms"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}